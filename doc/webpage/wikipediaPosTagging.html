<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 2.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
	<link rel="icon" type="image/ico" href="images/strus.ico" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Wikipedia to XML conversion for Strus." />
	<meta name="keywords" content="conversion Wikipedia data dump to XML" />
	<meta name="author" content="Patrick Frey &lt;patrickpfrey (a) yahoo (dt) com&gt;" />
	<link rel="stylesheet" type="text/css" href="text-profile.css" title="Text Profile" media="all" />
	<title>Wikipedia part of speech tagging</title>
</head>

<body>
<div id="wrap">
	<div id="content">
		<h1>Part of speech tagging of the Wikipedia collection for information retrieval</h1>

<h2>Intention</h2>
<p class="description">
The part of speech tagging of the Wikipedia collection for the <i>Strus</i> search engine intends to address the needs of a search engine only.
It is not a general purpose approach and not a start to such an approach. An attempt to take this POS tagging as base for other purposes will most likely fail.
The POS tagging implemented here aims to distinguish between verbs, adverbs and adjectives, nouns and entities and it tries to resolve personal pronoun references.
Not more.
</p>

<h2>Tags</h2>
<p class="description">
The following list describes the tags assigned to words or sequences of words in a document. The base document structure is the one described <a href="wikipediaToXML.html">here</a>.
The POS tags are assigned to content to '&lt;text&gt;' tags. The assignements of the tags is flat, there are no structures described with the tags. 
Every element or sequence of elements is uniquely tagged by POS tags. A POS tag is one of the following:
<ul>
CX
<li><b>V</b>:&nbsp;&nbsp;&nbsp; Verb</li>
<li><b>M</b>:&nbsp;&nbsp;&nbsp; Modal determiner</li>
<li><b>A</b>:&nbsp;&nbsp;&nbsp; Adverb or adjectiv</li>
<li><b>E</b>:&nbsp;&nbsp;&nbsp; Sequence of names forming a named entity identified by some heuristics. An entity 'E' tag may have an id attribute with the complete name referred to, if the name in the tag is not complete.</li>
<li><b>N</b>:&nbsp;&nbsp;&nbsp; Sequence of nouns forming a noun entity identified by some heuristics.</li>
<li><b>C</b>:&nbsp;&nbsp;&nbsp; Counter or number.</li>
<li><b>R</b>:&nbsp;&nbsp;&nbsp; Personal pronoun reference with an id attribute with the text of the entity referred to, e.g. "because &lt;R id=&apos;Mick Jagger&apos;&gt;he&lt;/R&gt; was"</li>
<li><b>P</b>:&nbsp;&nbsp;&nbsp; Punctuation marker splitting different parts of a sentence (tag without content, e.g. '&lt;P/&gt;'</li>
<li><b>T</b>:&nbsp;&nbsp;&nbsp; Sentence termination marker (tag without content, e.g. '&lt;T/&gt;'</li>
<li><b>W</b>:&nbsp;&nbsp;&nbsp; Wh-determiner/pronoun/adverb</li>
<li><b>U</b>:&nbsp;&nbsp;&nbsp; URI/URL reference, e.g. '&lt;U&gt;example.com&lt;/U&gt;'</li>
<li><b>X</b>:&nbsp;&nbsp;&nbsp; Existential there</li>
</ul>
The tag names do not correspond to <a href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html">the Penn Treebank tag names</a> 
because this would be misleading. The reduction to a small set of tags is intentional here.
</p>

<h2>Conversion</h2>
<p class="description">
The enriching of the Wikipedia collection english with POS tags is part of the conversion process of the Wikimedia format, but it is separated from it.
The basic POS tagging was done with a script using the output of <a href="https://spacy.io">SpaCy</a> and some heuristics to resolve entities referenced by partial names or personal pronouns.
</p>
<h2>Conversion script</h2>
<p class="description">The following shell function (excerpt from source in <a href="https://raw.githubusercontent.com/patrickfrey/strusWikipediaSearch/master/scripts/install_data.sh">scripts/install_data.sh</a>).
shows the conversion for one directory of the <a href="wikipediaToXML.html">XML converted from the original dump</a>. One such directory contains up to 1000 wikipedia articles.
<pre>
processPosTagging() {
    # [0] Some variable initializations
    # DID = sub directory id
    DID=$1
    # NLPCONV = script doing the conversion of file with multiple textdumps into a file with multiple structure dumps 
    #	with lines with 3 elements separated by tabs: (type,value,referenced value)
    NLPCONV=$SCRIPTPATH/strusnlp.py
    # Make output deterministic
    PYTHONHASHSEED=123

    # [1] Call a strus program to scan the Strus Wikipedia XML generated in the previous step from the Wikimedia dump.
    #	the program creates a text dump in /srv/wikipedia/pos/$DID.txt with all the selected contents as input for the
    #	POS tagging script.
    strusPosTagger -I -x xml -C XML -D '; ' -X '//pagelink@id' -Y '##' -e '//pagelink()' -e '//weblink()' -e '//text()' -e '//attr()' -e '//char()' -e '//math()' -e '//code()' -e '//bibref()' -E '//mark' -E '//text' -E '//entity' -E '//attr' -E '//attr~' -E '//quot' -E '//quot~' -E '//pagelink' -E '//weblink' -E '//tablink' -E '//citlink' -E '//reflink' -E '//tabtitle' -E '//head' -E '//cell' -E '//bibref' -E '//time' -E '//char' -E '//code' -E '//math' -p '//heading' -p '//table' -p '//citation' -p '//ref' -p '//list' -p '//cell~' -p '//head~' -p '//heading~' -p '//list~' -p '//br' /srv/wikipedia/xml/$DID /srv/wikipedia/pos/$DID.txt
    EC="$?"
    if [ "$EC" != "0" ]; then
        echo "Error creating POS tagger input: $EC" > /srv/wikipedia/err/$DID.txt
    fi

    # [2] Call the POS tagging script with the text dumps in /srv/wikipedia/pos/$DID.txt and write the output to /srv/wikipedia/tag/$DID,txt
    cat /srv/wikipedia/pos/$DID.txt | $NLPCONV -S -C 100 > /srv/wikipedia/tag/$DID.txt
    EC="$?"
    if [ "$EC" != "0" ]; then
        echo "Error in POS tagger script: $EC" > /srv/wikipedia/err/$DID.txt
    fi

    # [3] Merge the output of the POS tagging script with the original XML in /srv/wikipedia/xml/$DID/
    #	and write a new XML file with the same name into /srv/wikipedia/nlpxml/$DID/
    strusPosTagger -x ".xml" -C XML -e '//pagelink()' -e '//weblink()' -e '//text()' -e '//attr()' -e '//char()' -e '//math()' -e '//code()' -e '//bibref()' -o /srv/wikipedia/nlpxml/$DID /srv/wikipedia/xml/$DID /srv/wikipedia/tag/$DID.txt
    EC="$?"
    if [ "$EC" != "0" ]; then
        echo "Error tagging XML with POS tagger output: $EC" > /srv/wikipedia/err/$DID.txt
    fi
    # [4] Cleanup temporary files
    rm /srv/wikipedia/pos/$DID.txt
    rm /srv/wikipedia/tag/$DID.txt
}
</pre>
The function is called with the sub directory name consisting of 4 digits. The following example shows such a call:
<pre>
processPosTagging 1234
</pre>
</p>

<h2>Complexity</h2>
<p class="description">
The conversion of the Wikipedia collection English on an Intel(R) Core(TM) i7-6800K CPU 3.40GHz with 64 G RAM and a GTX 1060 GPU will presumably last 20 days
(number extrapolated from the conversion of 10% of the collection). 
Detailed numbers will follow.
</p>

<h2>Example Output: XML document with POS tagging</h2>
<p class="description">
<a href="wikipediaExampleXML_POS.html">This example XML document</a> illustrates the output generated by POS tagging process from the plain XML.
There are still bugs to fix, but the results start to be usable.
</p>

</div>
</div>
</body>
</html>
